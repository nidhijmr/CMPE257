{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 4 - Logistic Regression\n",
    "Course code : CMPE-257 \n",
    "Group name : Seekers \n",
    "Members :\n",
    "\n",
    "               * Anuradha Rajashekar(012409956)\n",
    "               * Ashwini Shankar Narayan(012506910)\n",
    "               * Nidhi Jamar(010070593)\n",
    "               * Sindhu Goudru Shivanandappa Patil(010823683)\n",
    "               \n",
    "## 1. Data Story  \n",
    "The data in the dataset is from a real Czech bank from 1999. The data is about clients and their accounts and has relation account, client, disposiiton,permanent order, transaction, loan, credit card and demographic data. Relations 'loans' and 'credit card' describe some services which bank offers to its clients. More credit cards can be issued to an account but atmost one loan can be granted for an account.\n",
    "The business objective is to analyze the transactional behavior of the customers and predict the loan approval status for the same customers.This is useful in cases where credit card companies provide pre approved loans for customers based on their payment and other factors. To acheive this, the below mentioned steps are followed,\n",
    "\n",
    "1. Data preparation and adding account details - Nidhi Jamar\n",
    "2. Identifying the categorical value from the features in dataset - Ashwini Shankar Narayan\n",
    "3. Applying Logistic Regression on the identified column - Sindhu Goudru Shivanandappa Patil\n",
    "4. Predicting the accuracy - Anuradha Rajashekar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Selection\n",
    "Dataset Link : https://data.world/lpetrocelli/czech-financial-dataset-real-anonymized-transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "In data preparation step, we read and preprocess the data to identify and remove invlaid values such as ? or NA. Here, we read and parse all the csv files in the dataset using the pandas dataframe.Pandas provide a unique advantage over other libraries in preprocessing the data by providing inbuilt APIs for all the math operations on selected row/column or full dataset. If there are any invalid values, fill it with the median value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "trans_d = pd.read_csv(\"data/trans.csv\")\n",
    "loan_d = pd.read_csv(\"data/loan.csv\")\n",
    "account_d = pd.read_csv(\"data/account.csv\")\n",
    "client_d = pd.read_csv(\"data/client.csv\")\n",
    "disp_d = pd.read_csv(\"data/disp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the details about when the account was created.\n",
    "The loan dataset contains only loan details with accountid. No other information of the client is present in loan dataset. Therefore, we are adding account creation date, account login frequency, date of birth of the client and the district id - loaction of the branch to the loan dataset.\n",
    "The output of this section shows that there are no missing/ invalid values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_id                   0\n",
      "account_id                0\n",
      "date                      0\n",
      "amount                    0\n",
      "duration                  0\n",
      "payments                  0\n",
      "status                    0\n",
      "account_date              0\n",
      "account_loginfrequency    0\n",
      "account_district          0\n",
      "client_birthNumber        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add information about when the account was created\n",
    "_column_date = []\n",
    "_column_frequency = []\n",
    "_column_district = []\n",
    "_column_clientdob =[]\n",
    "for c in loan_d['account_id']:\n",
    "    _result = account_d.loc[account_d['account_id'] == c]\n",
    "    _column_date.append(_result['date'].iloc[0])\n",
    "    _column_frequency.append(_result['frequency'].iloc[0])\n",
    "    _column_district.append(_result['district_id'].iloc[0])\n",
    "    _result = disp_d.loc[disp_d['account_id'] == c]\n",
    "    _result = client_d.loc[client_d['client_id'] == _result['client_id'].iloc[0]]\n",
    "    _column_clientdob.append(_result['birth_number'].iloc[0])\n",
    "    \n",
    "loan_d['account_date'] = _column_date\n",
    "loan_d['account_loginfrequency'] = _column_frequency\n",
    "loan_d['account_district'] = _column_district\n",
    "loan_d['client_birthNumber'] = _column_clientdob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "missing = loan_d.isna().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identifying a categorical value form one of the columns in our dataset\n",
    "\n",
    "### Here, we are getting to know the possible unique values for status feature in loan dataset and login frequency in account dataset.\n",
    "The only two features with String values from all the datasets is 'status' from loan and 'account_loginfrequency'. Therefore, we need to convert them to integer values. \n",
    "From the output, we understand 'status' feature has 4 unique values: 'A', 'B', 'C' and 'D',\n",
    "where A stands for contract finished, no problem,\n",
    "      B stands for contract finished, loan not payed,\n",
    "      C stands for running contract, OK so far and\n",
    "      D stands for running contract, client in debt\n",
    "  'account_loginfrequency' - frequency of issuance of statements,  has 3 unique values 'POPLATEK TYDNE', 'POPLATEK MESICNE', 'POPLATEK PO OBRATU'   \n",
    "  where \"POPLATEK TYDNE\" stands for monthly issuance \n",
    "        \"POPLATEK TYDNE\" stands for weekly issuance \n",
    "        \"POPLATEK PO OBRATU\" stands for issuance after transaction \n",
    " \n",
    "Here, we are using index values of these feature tuples to set an integer value. For example, in 'status' feature class B willbe assigned integer value 0.\n",
    "\n",
    "The model is not able to differentiate between clients who have finished contract and who havenot finished contract clearly beacuse there is no column in loan dataset which says whether the contract is finished or not. Therefore, We are reducing the number of classes to binary i.e two classes by classifying as clients who are paying loan regularly and who are not paying regularly.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in status :['B', 'A', 'C', 'D']\n",
      "Unique values in account login frequency :['POPLATEK TYDNE', 'POPLATEK MESICNE', 'POPLATEK PO OBRATU']\n"
     ]
    }
   ],
   "source": [
    "_statusUnique = list(loan_d['status'].unique())\n",
    "_freqUnique = list(loan_d['account_loginfrequency'].unique())\n",
    "print('Unique values in status :{}'.format(_statusUnique))\n",
    "print('Unique values in account login frequency :{}'.format(_freqUnique))\n",
    "loan_d['status'] = [_statusUnique.index(item) for item in loan_d['status']] \n",
    "loan_d['account_loginfrequency'] = [_freqUnique.index(item) for item in loan_d['account_loginfrequency']] \n",
    "_temp = []\n",
    "for d in loan_d['status']:\n",
    "    if(d==0 or d==3):\n",
    "        _temp.append(0)\n",
    "    else:\n",
    "        _temp.append(1)\n",
    "loan_d['binary_status']  = _temp        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are splitting the dataset into training data and testing data. We are considering 70% of the data for training and 30% of the data to test and predicting the value for column 'status'. We are splitting the dataset into training data and testing data both for 4 class classification of 'status' and binary classification of 'status' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "cols = list(loan_d.columns)\n",
    "cols.remove('loan_id')\n",
    "cols.remove('account_id')\n",
    "cols.remove('status')\n",
    "cols.remove('binary_status')\n",
    "X = loan_d[cols].iloc[ :, 0:].values\n",
    "Y = loan_d['status']\n",
    "Y_bin = loan_d['binary_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X, Y_bin, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Applying Logistic Regression on 'status' feature\n",
    "In this step, we are trying to predict the value of 'status' feature by applying Logistic Regression on a random value  in test dataset. For the test dataset, after applying logistic regression, the ground truth value and predicted value is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 class logistic regression   index :  196 , predicted :  2 , Ground truth :  2\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "logreg_bin = LogisticRegression(C=1e5)\n",
    "logreg_bin.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "num = np.random.randint(low=0, high=np.shape(X_test)[0], size=1)[0]\n",
    "result=logreg.predict(X_test[num,:].reshape(1, -1))[0]\n",
    "gt= y_test[num]\n",
    "print('4 class logistic regression   index : ',num,', predicted : ',result,', Ground truth : ',gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Binary class logistic regression   index :  103 , predicted :  1 , Ground truth :  1\n"
     ]
    }
   ],
   "source": [
    "num = np.random.randint(low=0, high=np.shape(X_test_bin)[0], size=1)[0]\n",
    "result=logreg_bin.predict(X_test_bin[num,:].reshape(1, -1))[0]\n",
    "gt= y_test_bin[num]\n",
    "print(' Binary class logistic regression   index : ',num,', predicted : ',result,', Ground truth : ',gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicting the precision and recall for the column 'status'\n",
    "After the machine is trained with 70% dataset, we are trying to predict the accuracy of the test data upon appying Logistic Regression. We can observe, for 4 class 'status' feature, the precision is 60% and recall is 67%. This is beacuse the model was not able to clearly distinguish between clients who belong to classes 'A' and 'C'- who are paying loan regularly and classes 'B' and 'D' - who are not paying loan regulalry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the classification report and confusion matrix.\n",
    "The classification report consists of precision, recall, f1- score and support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for 4 class logistic regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.70      0.50      0.58        62\n",
      "          2       0.67      0.91      0.78       117\n",
      "          3       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.60      0.67      0.62       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print('Metrics for 4 class logistic regression\\n',classification_report(y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making 'status' feature as binary, the precision increased to 76% and recall increased to 87% meaning the model is now able to clearly distinguish between clients paying loan regularly and not paying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for binary class logistic regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        26\n",
      "          1       0.87      1.00      0.93       179\n",
      "\n",
      "avg / total       0.76      0.87      0.81       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "Y_pred_bin = logreg_bin.predict(X_test_bin)\n",
    "print('Metrics for binary class logistic regression\\n',classification_report(y_test_bin, Y_pred_bin))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix gives the true positives, true negatives, false positives and false negatives. The confusion matrix of binary class logistic regression has less false positives compared to 4 class logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of 4 class logistic regression\n",
      " [[  0   5   6   0]\n",
      " [  0  31  31   0]\n",
      " [  0   8 107   2]\n",
      " [  0   0  15   0]]\n",
      "\n",
      "\n",
      "Confusion matrix of binary class logistic regression\n",
      " [[  0  26]\n",
      " [  0 179]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, Y_pred)\n",
    "print('Confusion matrix of 4 class logistic regression\\n',confusion_matrix)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test_bin, Y_pred_bin)\n",
    "print('\\n\\nConfusion matrix of binary class logistic regression\\n',confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss why you chose that attribute/feature and what you are trying to learn from the classification.\n",
    "\n",
    "Logistic Regression needs a categorical value to do the classificcation. Our dataset has only 2 features with categorical vlaues and 'status' feature in loan dataset and 'account_loginfrequency' feature in account dataset. Status feature is a good candidate to be considered for classification which predicts to which clients loan approval can be done and for whom not to approve the loan. The classification done for loan status basically helps banks or credit card companies to predict candidates for loan approval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does this further develop the story you are telling or discovering about your data set and business problem you are trying to solve?\n",
    "\n",
    "By classifying clients who pay loan regularly and who do not, banks or credit card companies can predict the defaulters for loan payment and approve the loan only to customers are pay regularly.\n",
    "Our business objective is to give promotions to clients based on their payments and other factors. In such cases, this classification helps in identifying clients for loan pre-approval who are not defaulters.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
